{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0 author                                               link  \\\n",
      "0           0    mrk  https://ceticismopolitico.com/2017/11/30/katia...   \n",
      "1           1   None  https://ceticismopolitico.com/2017/11/24/dr-ra...   \n",
      "2           2   None  https://afolhabrasil.com.br/politica/reinaldo-...   \n",
      "3           3   None  https://www.diariodobrasil.org/relatorio-assus...   \n",
      "4           4   None  https://www.diariodobrasil.org/radialista-amer...   \n",
      "\n",
      "   category date_of_publication  number_of_tokens  \\\n",
      "0  politica          2017-11-30               211   \n",
      "1  politica          2017-11-24               289   \n",
      "2  politica          2017-05-23               304   \n",
      "3  politica          24/07/2017               639   \n",
      "4  politica          25/07/2017               128   \n",
      "\n",
      "   number_of_word_without_ponctuation  number_of_types  \\\n",
      "0                                 185              120   \n",
      "1                                 254              163   \n",
      "2                                 275              170   \n",
      "3                                 572              316   \n",
      "4                                 111               82   \n",
      "\n",
      "  number_of_links_inside_the_news  number_of_words_in_upper_case  ...  \\\n",
      "0                               0                              6  ...   \n",
      "1                               0                              0  ...   \n",
      "2                               0                              0  ...   \n",
      "3                               1                             14  ...   \n",
      "4                               0                              1  ...   \n",
      "\n",
      "   number_of_pronoums  pausality  number_of_characters  \\\n",
      "0                  26   2.000000                   815   \n",
      "1                  20   2.500000                  1205   \n",
      "2                  18   1.812500                  1344   \n",
      "3                  34   2.680000                  3122   \n",
      "4                  12   0.894737                   515   \n",
      "\n",
      "   average_sentence_length  average_word_length  percentage_of_spelling_erros  \\\n",
      "0                 14.23080              4.40541                      0.000000   \n",
      "1                 18.14290              4.74409                      0.007874   \n",
      "2                 17.18750              4.88727                      0.003636   \n",
      "3                 22.88000              5.45804                      0.001748   \n",
      "4                  5.84211              4.63964                      0.000000   \n",
      "\n",
      "   emotiveness  diversity                                       preprocessed  \\\n",
      "0     0.263158   0.648649  katia abreu diz vai colocar expulsao moldura r...   \n",
      "1     0.241667   0.641732  dr ray peita bolsonaro chamao \" conservador fa...   \n",
      "2     0.127820   0.618182  reinaldo azevedo desmascarado policia federal ...   \n",
      "3     0.229008   0.552448  relatorio assustador bndes mostra dinheiro pub...   \n",
      "4     0.269231   0.738739  radialista americano fala sobre pt vendem ilus...   \n",
      "\n",
      "   label  \n",
      "0   fake  \n",
      "1   fake  \n",
      "2   fake  \n",
      "3   fake  \n",
      "4   fake  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('complete_dataframe.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['katia', 'abreu', 'diz', 'vai', 'colocar', 'expulsao', 'moldura', 'reclamar', 'senadora', 'katia', 'abreu', 'partidoto', 'disse', 'expulsao', 'pmdb', 'resultado', 'acao', 'cupula', 'atual', 'legenda', 'segundo', 'oportunista', '\"', 'amanha', 'vou', 'botar', 'moldura', 'dourada', 'expulsao', 'porque', 'maos', 'onde', 'veio', 'atestado', 'boa', 'conduta', 'curriculo', 'pessoas', 'expulsaram', 'servem', 'pais', 'servem', 'pais', 'beneficios', 'proprios', '\"', 'disse', 'katia', 'abreu', 'ue', 'expulsao', 'algo', 'tao', 'bom', 'curriculo', 'tanta', 'choradeira', 'katia', 'sabemos', 'motivo', 'provavelmente', 'katia', 'valor', 'pt', 'partido', 'deveria', 'tela', 'absorvido', 'parece', 'pt', 'gostava', 'katia', 'somente', 'ficasse', 'entrincheirada', 'dentro', 'pmdb', 'rebaixar', 'demais', 'resta']\n",
      "['katia', 'abreu', 'diz', 'vai', 'colocar', 'expulsao', 'moldura', 'reclamar', 'senadora', 'katia', 'abreu', 'partidoto', 'disse', 'expulsao', 'pmdb', 'resultado', 'acao', 'cupula', 'atual', 'legenda', 'segundo', 'oportunista', 'amanha', 'vou', 'botar', 'moldura', 'dourada', 'expulsao', 'porque', 'maos', 'onde', 'veio', 'atestado', 'boa', 'conduta', 'curriculo', 'pessoas', 'expulsaram', 'servem', 'pais', 'servem', 'pais', 'beneficios', 'proprios', 'disse', 'katia', 'abreu', 'ue', 'expulsao', 'algo', 'tao', 'bom', 'curriculo', 'tanta', 'choradeira', 'katia', 'sabemos', 'motivo', 'provavelmente', 'katia', 'valor', 'pt', 'partido', 'deveria', 'tela', 'absorvido', 'parece', 'pt', 'gostava', 'katia', 'somente', 'ficasse', 'entrincheirada', 'dentro', 'pmdb', 'rebaixar', 'demais', 'resta']\n"
     ]
    }
   ],
   "source": [
    "import string \n",
    "preprocessed_split=df['preprocessed'].apply(lambda x: x.split())\n",
    "\n",
    "print(preprocessed_split[0])\n",
    "\n",
    "#remove pontuação\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in preprocessed_split[0]]\n",
    "\n",
    "#remove strings vazias\n",
    "stripped = [string for string in stripped if string != '']\n",
    "print(stripped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Load vectors directly from the file\n",
    "# utilizar os modelos provenientes de http://nilc.icmc.usp.br/embeddings\n",
    "model = KeyedVectors.load_word2vec_format('skip_s300.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 300)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "word = preprocessed_split[0]\n",
    "# as palavras que não estão no vocabulários são substituidas por 'unk' = unknown\n",
    "word = [w if w in model.vocab else 'unk' for w in word]\n",
    "\n",
    "# tokeniza as palavras \n",
    "vectors = [model[w] for w in word if w in model.vocab]\n",
    "np.array(vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index label                                  preprocessed_news\n",
      "0      0  fake  katia abreu diz vai colocar expulsao moldura n...\n",
      "1      1  fake  ray peita bolsonaro conservador fake entrevist...\n",
      "2      2  fake  reinaldo azevedo desmascarado policia federal ...\n",
      "3      3  fake  relatorio assustador bndes mostra dinheiro pub...\n",
      "4      4  fake  radialista americano fala sobre pt vendem ilus...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('preprocessed/pre-processed.csv')\n",
    "print(df.head(5))\n",
    "\n",
    "preprocessed_split=df['preprocessed_news'].apply(lambda x: x.split())\n",
    "\n",
    "preprocessed_split2 = preprocessed_split .apply(lambda x: [w if w in model.vocab else 'unk' for w in x])\n",
    "\n",
    "vector = preprocessed_split2.apply(lambda x:  [model[w] for w in x if w in model.vocab])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "averaged_vector = vector.apply(lambda x: np.mean(np.array(x),axis=0))\n",
    "\n",
    "print(averaged_vector[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack( averaged_vector, axis=0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['label'].apply(lambda x:float(x=='true')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 300) (4320,)\n",
      "(1440, 300) (1440,)\n",
      "(1440, 300) (1440,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, test_size=y_test.shape[0], random_state=0)\n",
    "\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model =  make_pipeline(PolynomialFeatures(2),StandardScaler(),LogisticRegression(penalty='none',max_iter=10000))\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_val,y_val))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic: f1=0.866 auc=0.881\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "# predict probabilities\n",
    "lr_probs = model.predict_proba(X_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs = lr_probs[:, 1]\n",
    "# predict class values\n",
    "yhat = model.predict(X_test)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, lr_probs)\n",
    "lr_f1, lr_auc = f1_score(y_test, yhat), auc(lr_recall, lr_precision)\n",
    "# summarize scores\n",
    "print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
